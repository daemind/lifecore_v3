# LifeCore V3

**Agent adaptatif fractal avec planification**

Un framework gÃ©nÃ©rique pour systÃ¨mes autonomes: drones, usines, voitures, robots...

## ğŸ¯ Concepts ClÃ©s

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      LifeCore Node                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  GOALS      â†’ Objectifs Ã  atteindre                         â”‚
â”‚  NEEDS      â†’ Besoins homÃ©ostatiques (gÃ©nÃ¨rent intentions) â”‚
â”‚  STRATEGY   â†’ Planification (A*, exploration, backtrack)    â”‚
â”‚  MEMORY     â†’ RÃ©utilisation directe des expÃ©riences         â”‚
â”‚  CHILDREN   â†’ Sous-systÃ¨mes fractals                        â”‚
â”‚  RESOURCES  â†’ Ressources partagÃ©es limitÃ©es                 â”‚
â”‚  LAWS       â†’ Contraintes externes (murs, vitesse...)       â”‚
â”‚  CAPABILITY â†’ Limites internes (vitesse max moteur...)      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    FLUX PRINCIPAL                           â”‚
â”‚  Goal â†’ Strategy â†’ Intention â†’ Capacity Feedback â†’ Effect   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Installation

```bash
pip install numpy
# Optionnel pour configs YAML:
pip install pyyaml
```

## ğŸš€ Quick Start

```python
from lifecore import LifeCore, Goal, Need
import numpy as np

# CrÃ©er un agent
agent = LifeCore(dims=4)

# Ajouter un objectif
agent.goals.push(Goal(
    target=np.array([10, 10, 0, 0]),
    name="reach_target"
))

# Obtenir l'intention
state = np.array([0, 0, 0, 0])
intention = agent.get_intention(state)
```

## ğŸ“ Structure

```
lifecore-v3-clean/
â”œâ”€â”€ lifecore/
â”‚   â”œâ”€â”€ core.py        (493 lignes) Agent principal + feedback rÃ©cursif
â”‚   â”œâ”€â”€ strategy.py    (332 lignes) 6 stratÃ©gies de planification
â”‚   â”œâ”€â”€ config.py      (338 lignes) Loader YAML/JSON
â”‚   â”œâ”€â”€ memory.py      (238 lignes) MÃ©moire tensorielle
â”‚   â”œâ”€â”€ resource.py    (218 lignes) Ressources partagÃ©es
â”‚   â”œâ”€â”€ coherence.py   (189 lignes) Couplage entre frÃ¨res
â”‚   â”œâ”€â”€ law.py         (185 lignes) Contraintes externes
â”‚   â”œâ”€â”€ capability.py  (180 lignes) CapacitÃ©s internes
â”‚   â”œâ”€â”€ activation.py  (161 lignes) Fonctions smooth (sigmoid, relu)
â”‚   â”œâ”€â”€ goal.py        (157 lignes) Objectifs
â”‚   â””â”€â”€ need.py        (112 lignes) Besoins homÃ©ostatiques
â”‚
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ drone_delivery.yaml    Service de livraison drone
â”‚   â”œâ”€â”€ autonomous_car.yaml    Voiture autonome
â”‚   â””â”€â”€ factory.yaml           Ligne de production
â”‚
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ maze_solver.py         RÃ©solution de maze
â”‚   â”œâ”€â”€ drone_delivery_service.py
â”‚   â”œâ”€â”€ rocket_resources.py    DÃ©monstration Ã©mergence
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ tests/
    â””â”€â”€ test_lifecore.py
```

## ğŸ”§ Configuration ParamÃ©trique

DÃ©finir un systÃ¨me entier en JSON/YAML:

```json
{
  "name": "Drone Fleet",
  "dims": 7,
  "resources": [{"name": "battery", "capacity": 1000}],
  "laws": [{"type": "speed_limit", "max": 15}],
  "hierarchy": {
    "name": "controller",
    "children": [
      {"name": "drone", "count": 5, "domain": [0,1,2]}
    ]
  }
}
```

```python
from lifecore.config import load_system
system = load_system("configs/drone_delivery.json")
```

## ğŸ§  StratÃ©gies Disponibles

| StratÃ©gie | Description |
|-----------|-------------|
| `DirectStrategy` | Ligne droite vers la cible |
| `ExplorationStrategy` | Essayer diffÃ©rentes directions |
| `BacktrackStrategy` | Revenir en arriÃ¨re si bloquÃ© |
| `DecomposeStrategy` | Diviser en waypoints |
| `AStarStrategy` | Planification de chemin |
| `CompositeStrategy` | Combiner plusieurs stratÃ©gies |

## ğŸ”„ Feedback RÃ©cursif

Les contraintes remontent du bas vers le haut:

```python
# Parent demande vitesse 10
intention = parent.get_intention(state)  # [10, 0, 0]

# Enfant (moteur) reporte ce qu'il peut faire
capacity = child.get_capacity(intention)  # [8, 0, 0] (limitÃ©)

# Parent ajuste son intention
adjusted = parent.get_recursive_intention(state)  # [8, 0, 0]
```

## âœ… Ce qui fonctionne

- [x] Architecture fractale (parent â†’ enfants)
- [x] Besoins â†’ intentions
- [x] MÃ©moire tensorielle avec rÃ©utilisation
- [x] Goals et GoalStack
- [x] Ressources partagÃ©es avec allocation par prioritÃ©
- [x] Lois (vitesse, murs, zones interdites, feux)
- [x] CapacitÃ©s internes (saturation douce)
- [x] Configuration YAML/JSON
- [x] StratÃ©gies basiques (exploration, backtrack)
- [x] Feedback rÃ©cursif des contraintes
- [x] Activation functions (sigmoid, smooth_threshold)

## ğŸš§ TODO - Prochaines Ã‰tapes

### Court terme
- [ ] **Vrai A*** - PrÃ©-calculer le chemin complet avant de bouger
- [ ] **CohÃ©rence automatique** - CoherenceNeed intÃ©grÃ© sans config manuelle
- [ ] **Tests unitaires complets** - Couvrir tous les modules

### Moyen terme
- [ ] **Mazes plus grands** - 50x50+ pour voir la stratÃ©gie Ã©merger
- [ ] **Apprentissage de stratÃ©gie** - MÃ©moriser des patterns de maze
- [ ] **Simulation temps rÃ©el** - Visualisation graphique
- [ ] **Multi-agent coordination** - Plusieurs LifeCore qui collaborent

### Long terme
- [ ] **Meta-learning** - Apprendre Ã  rÃ©soudre des mazes, pas juste ce maze
- [ ] **HiÃ©rarchie dynamique** - CrÃ©er/supprimer des enfants selon les besoins
- [ ] **LLM integration** - Intentions en langage naturel
- [ ] **DÃ©ploiement hardware** - Drones rÃ©els, robots

## ğŸ“„ License

MIT

## ğŸ‘¥ Auteur

BioMatrix-MVA / LifeCore Team
